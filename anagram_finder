import urllib.request
import sys
from collections import Counter


def find_strict_anagrams(user_input, max_words=5, split_limit=29999):
    # --- 1. SETUP & DICTIONARY ---
    print("[1/3] Loading Strict Dictionary (Filtering Abbreviations)...")
    url = "https://raw.githubusercontent.com/first20hours/google-10000-english/master/google-10000-english-no-swears.txt"

    try:
        with urllib.request.urlopen(url) as response:
            raw_words = response.read().decode('utf-8').splitlines()
    except Exception as e:
        print(f"Error: {e}")
        return

    # --- 2. THE STRICT FILTER ---
    # We remove anything that looks like a state code, acronym, or noise
    blacklist = {'ca', 'ny', 'tx', 'fl', 'wa', 'al', 'ok', 'id', 'oh', 'or', 'la'}

    clean_target = "".join(filter(str.isalpha, user_input.lower()))
    target_count = Counter(clean_target)

    candidates = []
    for word in raw_words:
        w = word.lower()
        # Rule 1: Must be longer than 2 letters OR be 'a'/'i'
        if len(w) < 3 and w not in ['a', 'i']:
            continue
        # Rule 2: Explicitly remove state codes/short-forms
        if w in blacklist:
            continue
        # Rule 3: Must fit in our letter pool
        w_count = Counter(w)
        if all(w_count[c] <= target_count[c] for c in w_count):
            candidates.append(w)

    candidates.sort(key=len, reverse=True)

    # --- 3. THE SOLVER ---
    print(f"[2/3] Searching for pure phrases in '{user_input}'...")

    found_hashes = set()
    matches = 0
    file_index = 1
    current_entries = 0
    current_file = None

    def get_file():
        nonlocal current_file, file_index, current_entries
        if current_file is None or current_entries >= split_limit:
            if current_file: current_file.close()
            fname = f"strict_anagrams_part{file_index}.txt"
            current_file = open(fname, "w")
            file_index += 1
            current_entries = 0
        return current_file

    def backtrack(path, pool):
        nonlocal matches, current_entries

        if sum(pool.values()) == 0:
            phrase_hash = tuple(sorted(path))
            if phrase_hash not in found_hashes:
                found_hashes.add(phrase_hash)
                matches += 1
                current_entries += 1

                phrase_str = " ".join(path).title()
                get_file().write(phrase_str + "\n")

                if matches % 100 == 0:
                    sys.stdout.write(f'\râœ¨ Found {matches} strict anagrams...')
                    sys.stdout.flush()
            return

        if len(path) >= max_words:
            return

        for word in candidates:
            if len(word) > sum(pool.values()): continue
            w_count = Counter(word)
            if all(pool[c] >= w_count[c] for c in w_count):
                backtrack(path + [word], pool - w_count)

    # Execution
    for i, root in enumerate(candidates):
        sys.stdout.write(f'\rProgress: {(i / len(candidates)) * 100:.1f}% ')
        backtrack([root], target_count - Counter(root))

    if current_file: current_file.close()
    print(f"\n[3/3] Done! Total: {matches} results across {file_index - 1} file(s).")


# --- RUN ---
u_in = input("Enter phrase: ")
find_strict_anagrams(u_in)
